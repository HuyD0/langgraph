# Default configuration for LangGraph MCP Agent
# These are the baseline defaults - can be overridden by environment-specific configs

# Model/LLM Configuration
model:
  endpoint_name: "databricks-claude-3-7-sonnet"
  system_prompt: "You are a helpful AI assistant with access to various tools."
  temperature: 0.7
  max_tokens: 4096

# MCP Server Configuration
mcp:
  managed_server_urls: []  # Will be set dynamically based on workspace
  custom_server_urls: []
  timeout: 30

# MLflow Configuration
mlflow:
  experiment_name: "/Shared/langgraph-mcp-agent"
  model_name: "langgraph_mcp_agent"
  run_name: "agent_run"

# Unity Catalog Configuration
unity_catalog:
  catalog_name: "main"
  schema_name: "default"

# Databricks Configuration
databricks:
  workspace_url: null  # Auto-detected from environment
  auth_type: "default"  # default, token, oauth

# Deployment Configuration
deployment:
  environment: "dev"
  log_level: "INFO"
  enable_tracing: true
  enable_mlflow_autolog: true

# Agent Behavior
agent:
  max_iterations: 10
  recursion_limit: 25
  enable_tool_validation: true
  stream_response: true
